{"cells":[{"metadata":{},"cell_type":"markdown","source":"# MNIST Digit Recognizer Classification\n\nThis notebook is applied on the famous MNIST Digit Recognizer Dataset for Multiclass Classification. \n\nSteps:\n- Data Collection\n- Digit Visualization\n- Preprocessing: Data Augmentation\n- Modelling with KNN\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/digit-recognizer/train.csv')\ntest = pd.read_csv('../input/digit-recognizer/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = train.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train.pop('label')\nX = train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize pixels"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nsome_digit = X.loc[0].values\nsome_digit_image = some_digit.reshape(28,28)\n\nplt.imshow(some_digit_image, cmap='binary')\nplt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.loc[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The image looks like the number 1 and the label confirms it. "},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing\n\n## Shift MNIST images\n\nNow we create a function that shiftes images in the desired direction and by the number of pixels we define. "},{"metadata":{},"cell_type":"markdown","source":"The next step is to perform data augmentation, so that we build a richer dataset by concatenating 4 new training sets, one for each direction."},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = y_train\ndata = X.values\n\ndef shift_images(direction='up', nr_pixels=1):\n        \n    if direction =='up':\n        data_shifted = [np.roll(x.reshape(28,28).ravel(), -nr_pixels, axis=0) for x in data]\n    if direction =='down':\n        data_shifted = [np.roll(x.reshape(28,28).ravel(), nr_pixels, axis=0) for x in data]\n    if direction =='left':\n        data_shifted = [np.roll(x.reshape(28,28), -nr_pixels, axis=1).ravel() for x in data]\n    if direction =='right':\n        data_shifted = [np.roll(x.reshape(28,28), nr_pixels, axis=1).ravel() for x in data]\n        \n    df_shifted = pd.DataFrame(data_shifted, index=X.index, columns=X.columns)\n    df_shifted['label'] = labels\n    \n    return df_shifted ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_up = shift_images(direction='up', nr_pixels=1)\ndf_down = shift_images(direction='down', nr_pixels=1)\ndf_right = shift_images(direction='right', nr_pixels=1)\ndf_left = shift_images(direction='left', nr_pixels=1)\n\ndf_train = pd.concat([df_train, df_up, df_down, df_right, df_left])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After this, we need to shuffle the new training set."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shuffle training set\ndf_train = df_train.sample(frac=1).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling"},{"metadata":{},"cell_type":"markdown","source":"For the selection of the model we choose the KNeighborsClassifier. \n\nFor hyperparameter tuning, GridSearchCV is the best option to search for the best (weight, n_neighbors) combination."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = df_train.pop('label')\nX = df_train\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nknn = KNeighborsClassifier()\n\n\nparameters = {'weights':['uniform', 'distance'], \n              'n_neighbors':[3, 6, 9]}\n\nclf = GridSearchCV(knn, parameters)\nclf.fit(X, y_train)\n\nprint(clf.best_params_)\nprint(clf.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = clf.predict(test)\n\noutput = pd.DataFrame({'ImageId': test.index.values, 'Label': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your pipeline submission was successfully saved!\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}