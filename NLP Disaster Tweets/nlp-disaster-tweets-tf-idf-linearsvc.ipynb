{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01776,
     "end_time": "2021-01-26T19:02:42.404604",
     "exception": false,
     "start_time": "2021-01-26T19:02:42.386844",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Simple Text Classification (TFIDF + LinearSVC)\n",
    "\n",
    "In this notebook, a simple text classification algorithm is developed for the Classification of Disaster Tweets. \n",
    "\n",
    "Steps:\n",
    "- Read Data.\n",
    "- Data Preprocessing\n",
    "- Modelling with TF-IDF and LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-01-26T19:02:42.442956Z",
     "iopub.status.busy": "2021-01-26T19:02:42.442066Z",
     "iopub.status.idle": "2021-01-26T19:02:42.448016Z",
     "shell.execute_reply": "2021-01-26T19:02:42.447243Z"
    },
    "papermill": {
     "duration": 0.028997,
     "end_time": "2021-01-26T19:02:42.448157",
     "exception": false,
     "start_time": "2021-01-26T19:02:42.419160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nlp-getting-started/sample_submission.csv\n",
      "/kaggle/input/nlp-getting-started/train.csv\n",
      "/kaggle/input/nlp-getting-started/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T19:02:42.485791Z",
     "iopub.status.busy": "2021-01-26T19:02:42.484462Z",
     "iopub.status.idle": "2021-01-26T19:02:42.566177Z",
     "shell.execute_reply": "2021-01-26T19:02:42.565475Z"
    },
    "papermill": {
     "duration": 0.100239,
     "end_time": "2021-01-26T19:02:42.566312",
     "exception": false,
     "start_time": "2021-01-26T19:02:42.466073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../input/nlp-getting-started/train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T19:02:42.606563Z",
     "iopub.status.busy": "2021-01-26T19:02:42.605631Z",
     "iopub.status.idle": "2021-01-26T19:02:42.641707Z",
     "shell.execute_reply": "2021-01-26T19:02:42.641107Z"
    },
    "papermill": {
     "duration": 0.058643,
     "end_time": "2021-01-26T19:02:42.641868",
     "exception": false,
     "start_time": "2021-01-26T19:02:42.583225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('../input/nlp-getting-started/test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T19:02:42.686141Z",
     "iopub.status.busy": "2021-01-26T19:02:42.685351Z",
     "iopub.status.idle": "2021-01-26T19:02:42.707945Z",
     "shell.execute_reply": "2021-01-26T19:02:42.706493Z"
    },
    "papermill": {
     "duration": 0.048574,
     "end_time": "2021-01-26T19:02:42.708166",
     "exception": false,
     "start_time": "2021-01-26T19:02:42.659592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n",
      "________________________________________\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3237 non-null   object\n",
      " 2   location  2158 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()\n",
    "print('_'*40)\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T19:02:42.754978Z",
     "iopub.status.busy": "2021-01-26T19:02:42.750103Z",
     "iopub.status.idle": "2021-01-26T19:02:42.758505Z",
     "shell.execute_reply": "2021-01-26T19:02:42.757752Z"
    },
    "papermill": {
     "duration": 0.032437,
     "end_time": "2021-01-26T19:02:42.758641",
     "exception": false,
     "start_time": "2021-01-26T19:02:42.726204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Save the 'Id' column\n",
    "train_ID = df_train['id']\n",
    "test_ID = df_test['id']\n",
    "\n",
    "#Now drop the  'Id' colum since it's unnecessary for  the prediction process.\n",
    "df_train.drop(\"id\", axis = 1, inplace = True)\n",
    "df_test.drop(\"id\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016113,
     "end_time": "2021-01-26T19:02:42.791583",
     "exception": false,
     "start_time": "2021-01-26T19:02:42.775470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T19:02:42.835958Z",
     "iopub.status.busy": "2021-01-26T19:02:42.835212Z",
     "iopub.status.idle": "2021-01-26T19:02:42.847786Z",
     "shell.execute_reply": "2021-01-26T19:02:42.846996Z"
    },
    "papermill": {
     "duration": 0.040011,
     "end_time": "2021-01-26T19:02:42.847945",
     "exception": false,
     "start_time": "2021-01-26T19:02:42.807934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword       61\n",
      "location    2533\n",
      "text           0\n",
      "target         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "keyword       26\n",
       "location    1105\n",
       "text           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NaN values:\n",
    "print(df_train.isnull().sum())\n",
    "df_test.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01814,
     "end_time": "2021-01-26T19:02:42.885356",
     "exception": false,
     "start_time": "2021-01-26T19:02:42.867216",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Missing Values\n",
    "\n",
    "### Keyword\n",
    "\n",
    "Replace NaN values by None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T19:02:42.931532Z",
     "iopub.status.busy": "2021-01-26T19:02:42.930831Z",
     "iopub.status.idle": "2021-01-26T19:02:42.934612Z",
     "shell.execute_reply": "2021-01-26T19:02:42.934040Z"
    },
    "papermill": {
     "duration": 0.030817,
     "end_time": "2021-01-26T19:02:42.934763",
     "exception": false,
     "start_time": "2021-01-26T19:02:42.903946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train['keyword'] = df_train['keyword'].fillna('None')\n",
    "df_test['keyword'] = df_test['keyword'].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017809,
     "end_time": "2021-01-26T19:02:42.970165",
     "exception": false,
     "start_time": "2021-01-26T19:02:42.952356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T19:02:43.019710Z",
     "iopub.status.busy": "2021-01-26T19:02:43.017114Z",
     "iopub.status.idle": "2021-01-26T19:02:43.024231Z",
     "shell.execute_reply": "2021-01-26T19:02:43.023507Z"
    },
    "papermill": {
     "duration": 0.035314,
     "end_time": "2021-01-26T19:02:43.024381",
     "exception": false,
     "start_time": "2021-01-26T19:02:42.989067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train['location'] = df_train['location'].fillna('None')\n",
    "df_test['location'] = df_test['location'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T19:02:43.079106Z",
     "iopub.status.busy": "2021-01-26T19:02:43.077172Z",
     "iopub.status.idle": "2021-01-26T19:02:43.128401Z",
     "shell.execute_reply": "2021-01-26T19:02:43.127410Z"
    },
    "papermill": {
     "duration": 0.084911,
     "end_time": "2021-01-26T19:02:43.128690",
     "exception": false,
     "start_time": "2021-01-26T19:02:43.043779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train[\"text\"]= df_train[\"keyword\"] + \" \" + df_train[\"location\"] + \" \"+df_train[\"text\"]\n",
    "df_test[\"text\"]= df_test[\"keyword\"] + \" \" + df_test[\"location\"] + \" \"+df_test[\"text\"]\n",
    "\n",
    "df_train=df_train.drop(\"keyword\",axis=1)\n",
    "df_train=df_train.drop(\"location\",axis=1)\n",
    "\n",
    "df_test=df_test.drop(\"keyword\",axis=1)\n",
    "df_test=df_test.drop(\"location\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019462,
     "end_time": "2021-01-26T19:02:43.166796",
     "exception": false,
     "start_time": "2021-01-26T19:02:43.147334",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T19:02:43.214608Z",
     "iopub.status.busy": "2021-01-26T19:02:43.213812Z",
     "iopub.status.idle": "2021-01-26T19:02:43.224762Z",
     "shell.execute_reply": "2021-01-26T19:02:43.224109Z"
    },
    "papermill": {
     "duration": 0.040473,
     "end_time": "2021-01-26T19:02:43.224944",
     "exception": false,
     "start_time": "2021-01-26T19:02:43.184471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove redundant samples\n",
    "df_train=df_train.drop_duplicates(subset=['text', 'target'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T19:02:43.268912Z",
     "iopub.status.busy": "2021-01-26T19:02:43.268102Z",
     "iopub.status.idle": "2021-01-26T19:02:45.435140Z",
     "shell.execute_reply": "2021-01-26T19:02:45.434349Z"
    },
    "papermill": {
     "duration": 2.190749,
     "end_time": "2021-01-26T19:02:45.435270",
     "exception": false,
     "start_time": "2021-01-26T19:02:43.244521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def clean(sen):\n",
    "    sentence = re.sub(\"http[s]*://[^\\s]+\",\" \",sen)\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "    \n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    \n",
    "    sentence = str(sentence).lower()\n",
    "    sentence = sentence.replace(\",000,000\", \"m\").replace(\",000\", \"k\").replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
    "                           .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
    "                           .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
    "                           .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
    "                           .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'s\", \" own\")\\\n",
    "                           .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n",
    "                           .replace(\"€\", \" euro \").replace(\"'ll\", \" will\")\n",
    "    sentence = re.sub(r\"([0-9]+)000000\", r\"\\1m\", sentence)\n",
    "    sentence = re.sub(r\"([0-9]+)000\", r\"\\1k\", sentence)\n",
    "    sentence = re.sub(r\"\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s\\/]*))*\", \"\", sentence)\n",
    "    sentence = sentence.replace(\"_\", \" \")\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "pstem = PorterStemmer()\n",
    "def clean_text(text):\n",
    "    text= text.lower()\n",
    "    text= re.sub('[0-9]', '', text)\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens=[pstem.stem(word) for word in tokens]\n",
    "    #tokens=[word for word in tokens if word not in stopwords.words('english')]\n",
    "    text = ' '.join(tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T19:02:45.505908Z",
     "iopub.status.busy": "2021-01-26T19:02:45.490417Z",
     "iopub.status.idle": "2021-01-26T19:02:54.300442Z",
     "shell.execute_reply": "2021-01-26T19:02:54.299595Z"
    },
    "papermill": {
     "duration": 8.84653,
     "end_time": "2021-01-26T19:02:54.300589",
     "exception": false,
     "start_time": "2021-01-26T19:02:45.454059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train['text'] = df_train['text'].apply(lambda s : clean(s))\n",
    "df_test['text'] = df_test['text'].apply(lambda s : clean(s))\n",
    "df_train['text'] = df_train['text'].apply(lambda s : clean_text(s))\n",
    "df_test['text'] = df_test['text'].apply(lambda s : clean_text(s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020386,
     "end_time": "2021-01-26T19:02:54.339530",
     "exception": false,
     "start_time": "2021-01-26T19:02:54.319144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T19:02:54.387490Z",
     "iopub.status.busy": "2021-01-26T19:02:54.386611Z",
     "iopub.status.idle": "2021-01-26T19:02:54.391110Z",
     "shell.execute_reply": "2021-01-26T19:02:54.391613Z"
    },
    "papermill": {
     "duration": 0.031896,
     "end_time": "2021-01-26T19:02:54.391816",
     "exception": false,
     "start_time": "2021-01-26T19:02:54.359920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = df_train.loc[:,df_train.columns != 'target']  # this time we want to look at the text\n",
    "y_train = df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T19:02:54.438963Z",
     "iopub.status.busy": "2021-01-26T19:02:54.438141Z",
     "iopub.status.idle": "2021-01-26T19:02:55.813911Z",
     "shell.execute_reply": "2021-01-26T19:02:55.813137Z"
    },
    "papermill": {
     "duration": 1.403188,
     "end_time": "2021-01-26T19:02:55.814055",
     "exception": false,
     "start_time": "2021-01-26T19:02:54.410867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('text', TfidfVectorizer(),\n",
       "                                                  'text')])),\n",
       "                ('clf', LinearSVC(loss='hinge'))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "     transformers=[\n",
    "         ('text', TfidfVectorizer(), 'text'),]\n",
    "    ,)\n",
    "\n",
    "text_clf = Pipeline([('preprocessor', preprocessor),\n",
    "                     ('clf', LinearSVC(loss='hinge'),),\n",
    "])\n",
    "\n",
    "# Feed the training data through the pipeline\n",
    "text_clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T19:02:55.890766Z",
     "iopub.status.busy": "2021-01-26T19:02:55.864752Z",
     "iopub.status.idle": "2021-01-26T19:02:55.960254Z",
     "shell.execute_reply": "2021-01-26T19:02:55.959389Z"
    },
    "papermill": {
     "duration": 0.125878,
     "end_time": "2021-01-26T19:02:55.960399",
     "exception": false,
     "start_time": "2021-01-26T19:02:55.834521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = text_clf.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T19:02:56.007625Z",
     "iopub.status.busy": "2021-01-26T19:02:56.006923Z",
     "iopub.status.idle": "2021-01-26T19:02:56.337146Z",
     "shell.execute_reply": "2021-01-26T19:02:56.336181Z"
    },
    "papermill": {
     "duration": 0.357748,
     "end_time": "2021-01-26T19:02:56.337293",
     "exception": false,
     "start_time": "2021-01-26T19:02:55.979545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'id': test_ID,\n",
    "                       'target': predictions})\n",
    "\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 19.551252,
   "end_time": "2021-01-26T19:02:56.468171",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-26T19:02:36.916919",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
