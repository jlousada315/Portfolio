{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Titanic Predictions \n\n## Get the Data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Explore the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.hist(bins=10, figsize=(20,15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.plot(kind='scatter', x='Age', y='Survived')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Looking for Correlations"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = train_data.corr()\ncorr_matrix['Survived'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['FamilySize'] = train_data['SibSp'] + train_data['Parch'] + 1\ntest_data['FamilySize'] = test_data['SibSp'] + test_data['Parch'] + 1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = train_data.corr()\ncorr_matrix['Survived'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fare\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_data['Fare'] = train_data.loc[train_data['Fare'] < 100]['Fare']\ntrain_data['Fare'].fillna(train_data['Fare'].median(), inplace=True)\n#test_data['Fare'] = test_data.loc[test_data['Fare'] < 100]['Fare']\ntest_data['Fare'].fillna(test_data['Fare'].median(), inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.Fare.hist(bins=10)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sex"},{"metadata":{"trusted":true},"cell_type":"code","source":"women = train_data.loc[train_data['Sex']=='female']['Survived']\nrate_women = sum(women)/len(women)\n\nprint(\"% of women who survived:\", rate_women)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"men = train_data.loc[train_data['Sex']=='male']['Survived']\nrate_men = sum(men)/len(men)\n\nprint(\"% of men who survived:\", rate_men)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-Hot encode Ticket\ntrain_data.Sex = pd.get_dummies(train_data.Sex)\ntest_data.Sex = pd.get_dummies(test_data.Sex)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Age\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Age'].fillna(train_data['Age'].median(), inplace=True)\ntest_data['Age'].fillna(test_data['Age'].median(), inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['IsAlone'] = 0\ntrain_data.loc[train_data['FamilySize'] == 1, 'IsAlone'] = 1\ntest_data['IsAlone'] = 0\ntest_data.loc[test_data['FamilySize'] == 1, 'IsAlone'] = 1\n\ntrain_data['Age*Class'] = train_data.Age * train_data.Pclass\ntest_data['Age*Class'] = test_data.Age * test_data.Pclass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"old = train_data.loc[train_data['Age'] > 45]['Survived']\nrate_old = sum(old)/len(old)\n\nprint(\"% of old people who survived:\", rate_old)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mid_age = train_data.loc[(train_data['Age'] <= 45) & (train_data['Age'] >= 15)]['Survived']\nrate_mid = sum(mid_age)/len(mid_age)\n\nprint(\"% of middle aged people who survived:\", rate_mid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"young = train_data.loc[train_data['Age'] < 15]['Survived']\nrate_young = sum(young)/len(young)\n\nprint(\"% of young people who survived:\", rate_young)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Age'] = pd.cut(train_data['Age'], bins=[0., 10., 25., 50, 80, np.inf], labels=[0,1,2,3,4]).astype(int)\ntest_data['Age'] = pd.cut(test_data['Age'], bins=[0., 10., 25., 50, 80, np.inf], labels=[0,1,2,3,4]).astype(int)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.Age","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing Values \n\nprint(train_data.isnull().sum())\n\ntrain_data[train_data.Embarked.isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.mode.chained_assignment = None  # default='warn'\n# Label Encoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\n\n\n#label encoder can't handle missing values\ntrain_data.Embarked = train_data.Embarked.fillna('None')\ntest_data.Embarked = test_data.Embarked.fillna('None')\n\n# Label encode Embarked \nlabel_encoder = LabelEncoder()\ntrain_data.Embarked = label_encoder.fit_transform(train_data.Embarked)\ntest_data.Embarked = label_encoder.transform(test_data.Embarked)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = train_data.corr()\ncorr_matrix['Survived'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"Fare\", \"SibSp\", \"Parch\",\"FamilySize\", \"Embarked\", \"IsAlone\"]\nX = train_data[features]\nX_test = test_data[features]\n\nprint(X)\n\nscoring_method = \"f1\"\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling\n\n## Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf_model = RandomForestClassifier()\n\nrf_params ={\n    'bootstrap': [True, False],\n    'max_depth': [10, None],\n    'max_features': ['auto', 'sqrt'],\n    'min_samples_leaf': [1, 2, 4],\n    'min_samples_split': [2, 5, 10],\n    'n_estimators': [100]}\n\nrf_gs = GridSearchCV(rf_model, rf_params, scoring=scoring_method, cv=8, n_jobs=4)\n\nrf_gs.fit(X, y)\nprint(rf_gs.best_params_)\nprint(rf_gs.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\ncross_val_score(rf_gs, X, y, cv=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = random_forest.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your pipeline submission was successfully saved!\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}